## Report

### Files and Folders
`checker.py` - admin interface - can add, rm or rep
`analysis.py` - performs the required analysis for subtasks a1 and a2
`loadbalancer/` - contains all the code for the loadbalancer
`server/` - contains all the code for the server
`output/` - contains the output graphs for subtasks a1 and a2

Output graphs for subtasks A1 and A2 are in the `output` directory
These graphs can be generated by running the `make analysis` command (do not run it without finishing this README)

The analysis is performed in `analysis.py`. Check the `main()` function, and the different subtasks will be shown under
different functions.

NOTE: Server integer IDs are internal to the load balancer in our implementation
We have chosen to expose only the server hostnames in all the analysis. Any hostname that's randomly generated is
prefixed with "server_". So, for example, a random hostname could be "server_upxztyn"

### Subtask A1

![a1_n_3.png](output%2Fa1_n_3.png)  
<u>Observation and View:</u> We can see that the 10k requests have been distributed
evenly among the 3 servers. This shows that the consistent hashing
algorithm is working as expected and that we have a reasonably
good hash function.

### Subtask A2: N = 2 to 6
Running A1 again for different values of N, we get the following plots.
![a2_n_2.png](output%2Fa2_n_2.png)
![a2_n_3.png](output%2Fa2_n_3.png)
![a2_n_4.png](output%2Fa2_n_4.png)
![a2_n_5.png](output%2Fa2_n_5.png)
![a2_n_6.png](output%2Fa2_n_6.png)

Average load = Total number of requests / Number of servers = 10000/N  
Unless there are requests being dropped, the average load will always be 10000/N.

![a2_line_plot.png](output%2Fa2_line_plot.png)

### Subtask A3 - resiliency when server crashes
![a3_1.png](output%2Fa3_1.png)
![a3_2.png](output%2Fa3_2.png)
![a3_3.png](output%2Fa3_3.png)
Through the above screenshots, we can see that when we have some number of servers
and we simulate a server crash by running `docker stop`, the load balancer automatically
spawwns a new server as soon as it detects that the server is down.
This can be seen above in the output of the `python checker.py` command. As you can see, no
`rm` command was entered, but the `rep` command's output changed because of the crash,
and then automatically, with no intervention from our side, the `repo` command's output changes
again and it shows that another server was spawned.

#### Subtask A4 - changing the hash functions
We modified the hash function for placing a virtual server on the ring
from `i^2 + j^2 + 2j + 25` to `i^3 + j^3 + 2j + 25`.
We think this is better because it distributes the servers more randomly
across the ring since the powers are higher. Because the powers are higher,
the delta between the hash values for different server IDs is also higher,
leading to a wider distribution and less clustering of servers near each other.

Similarly, we also modified the hash function for request mapping from `i^2 + 2i + 17`
to `i^3 + 2i^2 + 17`. This will also cause a wider dispersion when mapped onto the ring.

![a4_a2_n_2.png](output%2Fa4_a2_n_2.png)
![a4_a2_n_3.png](output%2Fa4_a2_n_3.png)
![a4_a2_n_4.png](output%2Fa4_a2_n_4.png)
![a4_a2_n_5.png](output%2Fa4_a2_n_5.png)
![a4_a2_n_6.png](output%2Fa4_a2_n_6.png)
### How to run?

```
# need to run only once
python -m venv venv
source venv/bin/activate
make setup

# run the following commands in the order given
# No Ctrl+C anywhere at any time
# If you do Ctrl+C, run "make stop" before doing "make run" again

make run

# Wait for a few seconds before running the next command
# so that the server is fully set up

make analysis
# At this point, the script will interactively ask you which subtask
# to execute. Enter the subtask number and press enter.


make stop


# If you want to manually test the server, you can use

make run
python checker.py

# The checker script is interactive, enter commands without any
# arguments like add, rm, rep, and they'll be executed with
# random server hostnames.
```
